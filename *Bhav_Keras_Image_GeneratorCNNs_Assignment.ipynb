{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "Bhav_Keras_Image_GeneratorCNNs_Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bs3537/DS-Unit-4-Sprint-3-Deep-Learning/blob/master/*Bhav_Keras_Image_GeneratorCNNs_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZq9_CnBHjFK",
        "colab_type": "text"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "<br></br>\n",
        "\n",
        "## *Data Science Unit 4 Sprint 3 Assignment 2*\n",
        "# Convolutional Neural Networks (CNNs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0lfZdD_cp1t5"
      },
      "source": [
        "# Assignment\n",
        "\n",
        "- <a href=\"#p1\">Part 1:</a> Pre-Trained Model\n",
        "- <a href=\"#p2\">Part 2:</a> Custom CNN Model\n",
        "- <a href=\"#p3\">Part 3:</a> CNN with Data Augmentation\n",
        "\n",
        "\n",
        "You will apply three different CNN models to a binary image classification model using Keras. Classify images of Mountains (`./data/mountain/*`) and images of forests (`./data/forest/*`). Treat mountains as the postive class (1) and the forest images as the negative (zero). \n",
        "\n",
        "|Mountain (+)|Forest (-)|\n",
        "|---|---|\n",
        "|![](./data/mountain/art1131.jpg)|![](./data/forest/cdmc317.jpg)|\n",
        "\n",
        "The problem is realively difficult given that the sample is tiny: there are about 350 observations per class. This sample size might be something that you can expect with prototyping an image classification problem/solution at work. Get accustomed to evaluating several differnet possible models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2c1Ga0dBN1go",
        "colab_type": "text"
      },
      "source": [
        "IMPORT LIBRARIES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vd0QdgidNrMe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "923qbFm71dBz",
        "colab_type": "code",
        "outputId": "eb37555a-58f9-4e4d-e5c3-95e4ee86acf5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lP4OnJqHjFN",
        "colab_type": "code",
        "outputId": "81a46291-fc88-4290-cb4d-1897c64b4b6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow\n",
        "import pandas as pd\n",
        "import itertools\n",
        "from tensorflow import keras\n",
        " \n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        " \n",
        "from tensorflow.keras.layers import Dense, Input, GlobalAveragePooling2D, Flatten\n",
        "from tensorflow.keras.models import Model, Sequential # This is the functional API\n",
        "from tensorflow.keras.optimizers import RMSprop, Adam, Nadam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img \n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "from tensorflow.keras import applications \n",
        "from keras.utils.np_utils import to_categorical \n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "import matplotlib.pyplot as plt \n",
        "import matplotlib.image as mpimg\n",
        "%matplotlib inline\n",
        "import math \n",
        "import sys\n",
        " "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Awpzjt2t0qaQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#CREATE MODEL\n",
        "\n",
        "new_model = Sequential()\n",
        "new_model.add(ResNet50(include_top=False, pooling='avg', weights='imagenet'))\n",
        "new_model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "# Say not to train first layer (ResNet) model. It is already trained\n",
        "new_model.layers[0].trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8GFbpEDcMNI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rlrop = ReduceLROnPlateau(monitor='val_loss', factor=0.001, patience=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJstBPhL1HB4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Compile the model\n",
        "\n",
        "new_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvpPXJxhnIFL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#IMAGE LABEL AND FEATURES GENERATION\n",
        " \n",
        "# loading up our datasets\n",
        "\n",
        "TRAINING_DIR = \"/content/drive/My Drive/Lambda DS_Unit 4 Deep Learning/CNNs/data/train\"\n",
        "\n",
        "VALIDATION_DIR = \"/content/drive/My Drive/Lambda DS_Unit 4 Deep Learning/CNNs/data/validation\"\n",
        " \n",
        "\n",
        "ImageDataGenerator = tensorflow.keras.preprocessing.image.ImageDataGenerator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_w6H6_EnvUN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "image_size = 255, 255\n",
        "\n",
        "datagen = ImageDataGenerator(preprocessing_function=preprocess_input) #uses Resnet's preprocess input function\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqj66QW4oV4S",
        "colab_type": "code",
        "outputId": "aa36d5e4-e4bb-4c01-ec1e-dba77c4d3c0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "\n",
        " \n",
        "train_generator = datagen.flow_from_directory(TRAINING_DIR,\n",
        "                                              batch_size=10,\n",
        "                                              class_mode='categorical',\n",
        "                                              target_size=(255, 255), \n",
        "                                              shuffle=True, \n",
        "                                              seed=42)\n",
        " \n",
        "\n",
        "validation_generator = datagen.flow_from_directory(VALIDATION_DIR,\n",
        "                                              batch_size=10,\n",
        "                                              class_mode='categorical',\n",
        "                                              target_size=(255, 255), \n",
        "                                              shuffle=True, \n",
        "                                              seed=42)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 519 images belonging to 2 classes.\n",
            "Found 182 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cgaV50QCPDAN",
        "colab_type": "text"
      },
      "source": [
        "TRAIN AND VALIDATE ON DATA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQIEp6TaXslW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "initial_epochs = 10  #can increase to 10\n",
        "#validation_steps=20\n",
        "\n",
        "#loss0,accuracy0 = model.evaluate(validation_generator, steps = validation_steps)\n",
        "\n",
        "#print(\"initial loss: {:.2f}\".format(loss0))\n",
        "#print(\"initial accuracy: {:.2f}\".format(accuracy0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6o0lqmNNRJc",
        "colab_type": "code",
        "outputId": "e5c47aa9-4287-455b-efef-03904483fa95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        }
      },
      "source": [
        "epochs = 10\n",
        "\n",
        "#batch_size=32\n",
        "\n",
        "stop = EarlyStopping(monitor='val_loss', mode='min', min_delta=0.001, patience=3, verbose=1)\n",
        "filepath=\"/content/drive/My Drive/Lambda DS_Unit 4 Deep Learning/CNNs/data/best_resnet_model_scenes_assignment_imagegeneratorv3.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='auto', save_freq='epoch')\n",
        "\n",
        "new_model.fit_generator(\n",
        "        train_generator,\n",
        "        epochs=epochs,\n",
        "        validation_data=validation_generator,\n",
        "        verbose=1,\n",
        "        steps_per_epoch=2000,\n",
        "        callbacks=[stop, checkpoint, rlrop], \n",
        "        validation_steps=800)\n",
        "\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-12-12266aed6654>:16: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/10\n",
            "2000/2000 [==============================] - ETA: 0s - loss: 0.0095 - accuracy: 0.9977\n",
            "Epoch 00001: val_loss improved from inf to 0.04062, saving model to /content/drive/My Drive/Lambda DS_Unit 4 Deep Learning/CNNs/data/best_resnet_model_scenes_assignment_imagegeneratorv3.hdf5\n",
            "2000/2000 [==============================] - 115s 58ms/step - loss: 0.0095 - accuracy: 0.9977 - val_loss: 0.0406 - val_accuracy: 0.9834 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "1999/2000 [============================>.] - ETA: 0s - loss: 2.8028e-04 - accuracy: 1.0000\n",
            "Epoch 00002: val_loss did not improve from 0.04062\n",
            "2000/2000 [==============================] - 114s 57ms/step - loss: 2.8016e-04 - accuracy: 1.0000 - val_loss: 0.0447 - val_accuracy: 0.9837 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "2000/2000 [==============================] - ETA: 0s - loss: 1.2756e-04 - accuracy: 1.0000\n",
            "Epoch 00003: val_loss did not improve from 0.04062\n",
            "2000/2000 [==============================] - 113s 57ms/step - loss: 1.2756e-04 - accuracy: 1.0000 - val_loss: 0.0457 - val_accuracy: 0.9833 - lr: 1.0000e-06\n",
            "Epoch 4/10\n",
            "2000/2000 [==============================] - ETA: 0s - loss: 1.2738e-04 - accuracy: 1.0000\n",
            "Epoch 00004: val_loss did not improve from 0.04062\n",
            "2000/2000 [==============================] - 113s 56ms/step - loss: 1.2738e-04 - accuracy: 1.0000 - val_loss: 0.0444 - val_accuracy: 0.9836 - lr: 1.0000e-09\n",
            "Epoch 00004: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f2b7cd930b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    }
  ]
}