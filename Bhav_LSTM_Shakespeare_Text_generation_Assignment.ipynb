{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "Bhav_LSTM_Shakespeare_Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bs3537/DS-Unit-4-Sprint-3-Deep-Learning/blob/master/Bhav_LSTM_Shakespeare_Text_generation_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3dL_HQOfnsQb",
        "colab_type": "text"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "<br></br>\n",
        "\n",
        "## *Data Science Unit 4 Sprint 3 Assignment 1*\n",
        "\n",
        "# Recurrent Neural Networks and Long Short Term Memory (LSTM)\n",
        "\n",
        "![Monkey at a typewriter](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3c/Chimpanzee_seated_at_typewriter.jpg/603px-Chimpanzee_seated_at_typewriter.jpg)\n",
        "\n",
        "It is said that [infinite monkeys typing for an infinite amount of time](https://en.wikipedia.org/wiki/Infinite_monkey_theorem) will eventually type, among other things, the complete works of Wiliam Shakespeare. Let's see if we can get there a bit faster, with the power of Recurrent Neural Networks and LSTM.\n",
        "\n",
        "This text file contains the complete works of Shakespeare: https://www.gutenberg.org/files/100/100-0.txt\n",
        "\n",
        "Use it as training data for an RNN - you can keep it simple and train character level, and that is suggested as an initial approach.\n",
        "\n",
        "Then, use that trained RNN to generate Shakespearean-ish text. Your goal - a function that can take, as an argument, the size of text (e.g. number of characters or lines) to generate, and returns generated text of that size.\n",
        "\n",
        "Note - Shakespeare wrote an awful lot. It's OK, especially initially, to sample/use smaller data and parameters, so you can have a tighter feedback loop when you're trying to get things running. Then, once you've got a proof of concept - start pushing it more!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "to68KIlEtF9m",
        "colab_type": "code",
        "outputId": "097e85f3-3140-456a-ce32-0adaa6efbe61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import tensorflow \n",
        "print(tensorflow.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0-rc3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgnhpL7F6AAj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a0f0282e-374f-420f-81b8-6e4a18b78fd7"
      },
      "source": [
        "from __future__ import print_function\n",
        "import tensorflow\n",
        "from tensorflow import keras\n",
        "from keras.callbacks import LambdaCallback\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.utils.data_utils import get_file\n",
        "import numpy as np\n",
        "import random\n",
        "import sys\n",
        "import io\n",
        "\n",
        "path = get_file(\n",
        "    '100-0.txt',\n",
        "    origin='https://www.gutenberg.org/files/100/100-0.txt')\n",
        "with io.open(path, encoding='utf-8') as f:\n",
        "    text = f.read().lower()\n",
        "print('corpus length:', len(text))\n",
        "\n",
        "chars = sorted(list(set(text)))\n",
        "print('total chars:', len(chars))\n",
        "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
        "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
        "\n",
        "# cut the text in semi-redundant sequences of maxlen characters\n",
        "maxlen = 40\n",
        "step = 3\n",
        "sentences = []\n",
        "next_chars = []\n",
        "for i in range(0, len(text) - maxlen, step):\n",
        "    sentences.append(text[i: i + maxlen])\n",
        "    next_chars.append(text[i + maxlen])\n",
        "print('nb sequences:', len(sentences))\n",
        "\n",
        "print('Vectorization...')\n",
        "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
        "for i, sentence in enumerate(sentences):\n",
        "    for t, char in enumerate(sentence):\n",
        "        x[i, t, char_indices[char]] = 1\n",
        "    y[i, char_indices[next_chars[i]]] = 1\n",
        "\n",
        "\n",
        "# build the model: a single LSTM\n",
        "print('Build model...')\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
        "model.add(Dense(len(chars), activation='softmax'))\n",
        "\n",
        "optimizer = RMSprop(learning_rate=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
        "\n",
        "\n",
        "def sample(preds, temperature=1.0):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)\n",
        "\n",
        "\n",
        "def on_epoch_end(epoch, _):\n",
        "    # Function invoked at end of each epoch. Prints generated text.\n",
        "    print()\n",
        "    print('----- Generating text after Epoch: %d' % epoch)\n",
        "\n",
        "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
        "        print('----- diversity:', diversity)\n",
        "\n",
        "        generated = ''\n",
        "        sentence = text[start_index: start_index + maxlen]\n",
        "        generated += sentence\n",
        "        print('----- Generating with seed: \"' + sentence + '\"')\n",
        "        sys.stdout.write(generated)\n",
        "\n",
        "        for i in range(400):\n",
        "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "            for t, char in enumerate(sentence):\n",
        "                x_pred[0, t, char_indices[char]] = 1.\n",
        "\n",
        "            preds = model.predict(x_pred, verbose=0)[0]\n",
        "            next_index = sample(preds, diversity)\n",
        "            next_char = indices_char[next_index]\n",
        "\n",
        "            sentence = sentence[1:] + next_char\n",
        "\n",
        "            sys.stdout.write(next_char)\n",
        "            sys.stdout.flush()\n",
        "        print()\n",
        "\n",
        "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
        "\n",
        "model.fit(x, y,\n",
        "          batch_size=128,\n",
        "          epochs=60,\n",
        "          callbacks=[print_callback])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.gutenberg.org/files/100/100-0.txt\n",
            "5783552/5777367 [==============================] - 3s 0us/step\n",
            "corpus length: 5573152\n",
            "total chars: 79\n",
            "nb sequences: 1857704\n",
            "Vectorization...\n",
            "Build model...\n",
            "Epoch 1/60\n",
            "1857704/1857704 [==============================] - 1306s 703us/step - loss: 1.6521\n",
            "\n",
            "----- Generating text after Epoch: 0\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \"e from thee going, he went wilful-slow,\n",
            "\"\n",
            "e from thee going, he went wilful-slow,\n",
            "    and thou art thou shall in the prove the proves to the can to the princes of the proves to the stranger to me.\n",
            "                                                                                                                                                                                                                                                                                             \n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \"e from thee going, he went wilful-slow,\n",
            "\"\n",
            "e from thee going, he went wilful-slow,\n",
            "    and that i will sing the kinds of the cassio.\n",
            "                                           exeunt\n",
            "\n",
            "\n",
            "\n",
            "      bernadis of the cap and a change of chear it.\n",
            "of heaven it soldiers and the devilner hand\n",
            "    the possesse of the stranger with her child to the\n",
            "    with your workly manting son poor princes of the princes and man of the see one\n",
            "    that more the womans where is the command\n",
            "    and one good\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"e from thee going, he went wilful-slow,\n",
            "\"\n",
            "e from thee going, he went wilful-slow,\n",
            "together, werrickned like knief? doth womene verits she's not these nature, root\n",
            "for a remembrus;                          ears of yorce: wores, and so beea,\n",
            "and may so toine the cosersmanress, if that bedwave.\n",
            "\n",
            "proyes.\n",
            "you good tong, resse.; to sensaness and your ropeny, the ties;\n",
            "and fie. vale with himself, been channy too.\n",
            "\n",
            "            enter one aisted,                               exeunt\n",
            "\n",
            "mor\n",
            "----- diversity: 1.2\n",
            "----- Generating with seed: \"e from thee going, he went wilful-slow,\n",
            "\"\n",
            "e from thee going, he went wilful-slow,\n",
            "begfnes as to wootlance. i will dimpoor onfer\n",
            "ay xa\n",
            "such aff' i cannot.\n",
            "i have passity-thels justs exprisout.\n",
            "\n",
            "ladrimens.\n",
            "what our drombit spate in puts.\n",
            "\n",
            "\n",
            "      yorken.\n",
            "till you drynding now.\n",
            "\n",
            "kingel.\n",
            "hele thedilor.\n",
            "\n",
            "first loft\n",
            "fhar brail, somery! there is be shun, and i’ll\n",
            "she foath jounted fleinn, dleed and verguous beating, his widsmon'd\n",
            "might drendtoue, liesary, but looks\n",
            "out my crare at grie\n",
            "Epoch 2/60\n",
            "1857704/1857704 [==============================] - 1302s 701us/step - loss: 1.5200\n",
            "\n",
            "----- Generating text after Epoch: 1\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \"u think?\n",
            "\n",
            "iago.\n",
            "think, my lord?\n",
            "\n",
            "othello\"\n",
            "u think?\n",
            "\n",
            "iago.\n",
            "think, my lord?\n",
            "\n",
            "othello.\n",
            "i will be the company the sons and love and so much and many many construment\n",
            "    the sentes and be and march and sent the commonject.\n",
            "    the start of the sons and be and sold me to the strength.\n",
            "    the company. what is the great saturned and all the constrant\n",
            "    and have the strength of the souls and lady the souls.\n",
            "    the constant the starrate shall be and so many many many by the strength\n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \"u think?\n",
            "\n",
            "iago.\n",
            "think, my lord?\n",
            "\n",
            "othello\"\n",
            "u think?\n",
            "\n",
            "iago.\n",
            "think, my lord?\n",
            "\n",
            "othello.\n",
            "i have with these near the strikes and find.\n",
            "\n",
            "             enter letre to parts of the to the shall be a longer.\n",
            "\n",
            " enter the supperus.\n",
            "i will constrate this armers when and your obbles.\n",
            "  third selugo. the by the proceed and strength.\n",
            "    and here far to seen not hold some the souls,\n",
            "    the strength of the old my loust and soul,\n",
            "    which which now he than i will shall fire\n",
            "when the limbly of f\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"u think?\n",
            "\n",
            "iago.\n",
            "think, my lord?\n",
            "\n",
            "othello\"\n",
            "u think?\n",
            "\n",
            "iago.\n",
            "think, my lord?\n",
            "\n",
            "othello.\n",
            "         cere lucius.\n",
            "i’ll will? i shall figry kindr sterfean,\n",
            "rome if they hem else laughter errality,\n",
            "missaping fortuness, uble\n",
            "as upwaldet while yes.\n",
            "    these bly by me no lost; and hall when it be a frarce\n",
            "and no soul-prince and anig. a sawn.\n",
            "\n",
            "and thousand\n",
            "returness's praise secret of troupt:\n",
            "pattice of give thy garmens and back of my war.\n",
            "whese divigus of grave! where is so why from me sho\n",
            "----- diversity: 1.2\n",
            "----- Generating with seed: \"u think?\n",
            "\n",
            "iago.\n",
            "think, my lord?\n",
            "\n",
            "othello\"\n",
            "u think?\n",
            "\n",
            "iago.\n",
            "think, my lord?\n",
            "\n",
            "othello.\n",
            "whyilche\n",
            "of, call up\n",
            "      pleaming,d many welk, it as helves\n",
            "you unless, vissalishaading, still slandoring,\n",
            "whhest dight o’er oute by in: farst not, to be lior? the\n",
            "  carriis.\n",
            "melcother refamibhalvase not living not in or scroke, comsin, she.\n",
            "\n",
            "\n",
            "      tent!\n",
            "and i ollest me of his robal! blowish ofly hand of\n",
            "master pypust nay winles.\n",
            "\n",
            "i hake, , ildrarce.\n",
            "prosphe, kingromon taphfortime, leot ear a\n",
            "Epoch 3/60\n",
            "1857704/1857704 [==============================] - 1284s 691us/step - loss: 1.4975\n",
            "\n",
            "----- Generating text after Epoch: 2\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \" thee to the very echo,\n",
            "that should appl\"\n",
            " thee to the very echo,\n",
            "that should apple to the state to the part and the state\n",
            "    the court of the word to make the state,\n",
            "    and the truth of the court and stand and the state.\n",
            "                                             "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:59: RuntimeWarning: divide by zero encountered in log\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                                                                                                                                                                                                                     \n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \" thee to the very echo,\n",
            "that should appl\"\n",
            " thee to the very echo,\n",
            "that should apple thee contine of my dear.\n",
            "\n",
            "bertram.\n",
            "a ground to poor world, thou hast not the\n",
            "    knows that what with the part of the bear the state\n",
            "    as thou do that all be stander; i say the done\n",
            "the father in the pantanty in the stratch\n",
            "    and say thou not to say you be here to the brother\n",
            "    this person in the strong all his love,\n",
            "    the warrant from the tays and on the frither;\n",
            "    and love and with t\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \" thee to the very echo,\n",
            "that should appl\"\n",
            " thee to the very echo,\n",
            "that should apply him, and he is knownly wey.\n",
            "  angelo. are my sister give\n",
            "do regre with have you light’s our nobglitities,\n",
            "    dlay dear stroke came of your forcaman\n",
            "none upon his bing to let cashings, ourer.\n",
            "    i doe stail ake, my master bathalens,\n",
            "for they see deniercal upon this face thou\n",
            "warwick our langegous ouite._]\n",
            "\n",
            " enter \n",
            "  reya. we do my teeth the encolniban not\n",
            "autalbe, hear panth foot tos\n",
            "    too do\n",
            "----- diversity: 1.2\n",
            "----- Generating with seed: \" thee to the very echo,\n",
            "that should appl\"\n",
            " thee to the very echo,\n",
            "that should appless my me-pob, hold me.   tima and fear, bul.\n",
            "  crodiand. like nengle.e? vossed steeray:\n",
            "stuce in through yestes; or ayary; sliboe'\n",
            "  uproam’ra. they have fanty fin'd\n",
            "    likefilm-latven passigy. give bring notter good volug's knowl,\n",
            "slab'd that man tooret or tingly, and upon\n",
            "the iach help, an in that winl; a moid aymate from our elchpilful.\n",
            "whither, oh’d.\n",
            "\n",
            "hotspur.\n",
            "and thou frenchcrauls\n",
            "on you. n\n",
            "Epoch 4/60\n",
            "1709696/1857704 [==========================>...] - ETA: 1:42 - loss: 1.4975Buffered data was truncated after reaching the output size limit."
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}